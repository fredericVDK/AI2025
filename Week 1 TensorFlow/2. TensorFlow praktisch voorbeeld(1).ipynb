{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Aan de slag met de Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit labo gaan we aan de slag met de __Fashion MNIST dataset__ die afbeeldingen van in totaal __70 000 Zalando artikelen__ bevat. \n",
    "</br>De afbeeldingen zijn in __grijswaarde, 28x28 pixels groot__, en kunnen aan één van de __10 klassen__ toegewezen worden.\n",
    "</br>Meer info: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "We ontwikkelen in deze notebook een neuraal netwerk dat voorspelt tot welke categorie elk artikel behoort. \n",
    "</br>Deze notebook is deels ingevuld, het is dan ook de bedoeling dat je deze zelf aanvult waar dit aangegeven staat (zowel de commando's als in tekstvorm). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importeren van libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importeer TensorFlow om aan de slag te gaan. Zorg ervoor dat je TensorFlow minstens versie 2.0.0 is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Laden van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken gebruik van de __Fashion MNIST dataset__. Deze kunnen we rechtstreeks downloaden via TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We laden de dataset in. Standaard worden via <code>load_data()</code> 60 000 trainingexamples en 10 000 testexamples ingeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De data omvat afbeeldingen in __grijswaarden__, waarbij elke pixel een waarde aanneemt tussen 0 (zwart) en 255 (wit). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__De labels van deze dataset:__ 0: T-shirt/top. 1: Broek. 2: Pullover. 3: Jurk. 4: Jas. 5: Sandaal. 6: Shirt. 7: Sneaker. 8: Tas. 9: Enkellaars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset overzicht:\")\n",
    "print(f\"Trainingsset grootte: {x_train.shape[0]} voorbeelden\")\n",
    "print(f\"Testset grootte: {x_test.shape[0]} voorbeelden\")\n",
    "print(f\"Afbeelding dimensies: {x_train.shape[1]}x{x_train.shape[2]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nu kunnen we de dataverdeling plotten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributie van samples per klasse\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Labels definiëren\n",
    "class_names = ['T-shirt/top', 'Broek', 'Pullover', 'Jurk', 'Jas',\n",
    "               'Sandaal', 'Shirt', 'Sneaker', 'Tas', 'Enkellaars']\n",
    "\n",
    "# Tel samples per klasse\n",
    "train_counts = np.bincount(y_train)\n",
    "test_counts = np.bincount(y_test)\n",
    "\n",
    "# Maak een bar plot\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, train_counts, width, label='Training set', color='skyblue')\n",
    "plt.bar(x + width/2, test_counts, width, label='Test set', color='lightgreen')\n",
    "\n",
    "# Voeg labels en titel toe\n",
    "plt.xlabel('Klasse')\n",
    "plt.ylabel('Aantal samples')\n",
    "plt.title('Distributie van samples per klasse in training- en testset')\n",
    "plt.xticks(x, class_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "\n",
    "# Voeg aantallen toe boven elke bar\n",
    "for i, count in enumerate(train_counts):\n",
    "    plt.text(i - width/2, count, str(count), ha='center', va='bottom')\n",
    "for i, count in enumerate(test_counts):\n",
    "    plt.text(i + width/2, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print ook de exacte aantallen\n",
    "print(\"\\nAantal samples per klasse:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"{name:12} - Training: {train_counts[i]:5d}, Test: {test_counts[i]:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bekijken van de dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vooraleer we ons model opstellen of gaan trainen is het belangrijk dat we weten hoe onze data eruit ziet. Daarom plotten we de __eerste 25 training examples__ uit onze dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
    "\n",
    "for i in range(25):\n",
    "\tpyplot.subplot(5, 5, i+1)\n",
    "\tpyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "    \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: normaliseer de data zodat elke pixel een waarde heeft binnen het interval [0,1] in plaats van [0,255] Dit zal toelaten efficienter te leren.\n",
    "'''\n",
    "x_train, x_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bouwen van een ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken een model door het __opeenstapelen van verschillende lagen__ via het <code>Sequential Model</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: \n",
    "De inputlaag is reeds gegeven. Dit zal praktisch altijd een laag zijn van het type Flatten, aangezien we een afbeelding in matrixvorm willen omzetten naar een vector.\n",
    "\n",
    "Implementeer vervolgens een hidden Dense laag met 128 neuron en de RELU activatiefunctie voor deze laag. \n",
    "\n",
    "Voorzie als laatste laag ook de juiste classificatielaag. Denk daarbij aan het aantal nodige neuronen in die laag.\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "'''\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # brengen van de input naar 1 dimensie\n",
    "  tf.keras.layers.Dense(128, activation=\"relu\")                                               # implementeert de operatie: output = activation(dot(input,kernel) + bias). Activation is de activatiefunctie, kernel zijn de gewichten, bias = bias vector.\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen ons model bekijken door het <code>model.summary()</code> commando. \n",
    "- In de eerste kolom vind je de laag en het type terug (Flatten = input, Dense = fully connected,..). \n",
    "- De tweede kolom geeft de output shape terug. Van de input weten we dat dit 784 is (28x28 pixels). Als je *None* ziet staan, wil dit zeggen dat deze dimensie niet vast staat. </br>Dit laat toe om bijvoorbeeld een variabel aantal trainingsexamples te gebruiken (aangezien dit niet als een constante in je model staat gedefinieerd).\n",
    "- De derde kolom geeft het aantal parameters weer. Voor de eerste hidden laag is dit bijvoorbeeld 785 (28x28 pixels + 1 bias term) x 128 (aantal neuronen in die laag) = 100480."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We hebben ons model opgesteld, maar op dit model is dit nog niet getraind.__ Toch kunnen we er al voorspellingen op uitvoeren, al zal ons dit nog geen zinnige voorspellingen geven. De gewichten van ons model zijn namelijk willekeurig toegekend. Bij wijze van oefening gaan we toch eens een voorspelling doen van een trainingsexample. Dit kan met <code>model.predict()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voorspelling van het eerste trainingsexample. We moeten eerst onze example reshapen zodat deze de juiste dimensies heeft\n",
    "example_nr = 0\n",
    "train_example = np.expand_dims(x_train[example_nr], axis=0)\n",
    "prediction = model.predict(train_example)\n",
    "print(prediction)\n",
    "\n",
    "# Weetje: je kan ook een voorspelling doen door rechtstreeks je trainingsexample aan je model te voegen. Dit zou dus hetzelfde resultaat moeten geven als bovenstaand commando.\n",
    "prediction = model(train_example)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor elke example zal ons model __een vector teruggeven van scores__. Deze scores geven een probabiliteit terug dat een example tot een bepaalde klasse behoort. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als output zie je een rij met die __10 elementen telt__. Deze waarden stellen de probabiliteiten voor dat het voorbeeld tot een klasse behoort. De tweede waarde in deze vector is dus de probabiliteit dat ons trainingsexample tot klasse 1 (= Trouser) behoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zien dat we zowel positieve als negatieve waarden in onze output-vector kunnen hebben. De reden hiervoor is dat er geen activatiefunctie is toegewezen aan onze laatste laag, waar onze voorspellingen uitkomen. Deze negatieve en positieve reële getallen in de vector zijn niet zo ideaal om te trainen. Gelukkig kunnen we hier iets aan doen door gebruik te maken van de <code>softmax</code> functie. Deze functie zet een vector van reële getallen om naar een vector met waarden tussen 0 en 1 waarbij de som van alle elementen = 1. Dit helpt het trainen sneller te convergeren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De <code>softmax</code> functie kunnen we oproepen dmv <code>tf.nn.softmax</code>. In onderstaand voorbeeld geven we onze net bekomen prediction vector mee, waarna deze wordt omgezet naar een softmax vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.nn.softmax(prediction).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definieren van de loss functie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vooraleer we ons netwerk gaan trainen, moeten we natuurlijk aangeven hoe we gaan meten hoe goed onze voorspellingen zijn.\n",
    "De loss functie van ons netwerk geeft aan hoe ver onze voorspelling ligt van de echte waarde. Afhankelijk van ons probleem (regressie of classificatie) hebben we keuze tussen verschillende functies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: Definieer de juiste loss functie voor voor ons probleem. \n",
    "\n",
    "Tip 1: bekijk ook de theorieslides waar je terugvindt welke lossfunctie kan gebruiken voor dit type probleem\n",
    "Tip 2: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "\n",
    "\n",
    "'''\n",
    "loss_fn = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het ongetrainde model geeft willekeurige probabilities. Gemiddelde zijn we 1/10 keer juist (er zijn 10 klassen, dus gemiddeld gokken we 1/10 goed).\n",
    "</br>Hierdoor ligt de initiele loss rond <code>tf.math.log(1/10) = 2.3.</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_fn(y_train[:1], prediction).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vooraleer we ons model gaan trainen kan worden, moet het model __gecompileerd__ worden. Stel de juiste, door jou net gekozen loss functie in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: kies een geschikte optimizer\n",
    "Tip 1: theorieslides\n",
    "Tip 2: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "'''\n",
    "optimizer = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kies vervolgens ook de metric waarop je wil evalueren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: kies een geschikte evaluatiemetric.\n",
    "Tip: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "'''\n",
    "\n",
    "metric = ['']\n",
    "model.compile(optimizer = optimizer, loss = loss_fn, metrics = metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainen en evalueren van het model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het is zover! We kunnen ons model nu gaan trainen (= <code>fitten</code>). Het zal daarbij gebruik maken van de gecompileerde model, dat een voorstelling is van ons model, onze optimizer, de lossfunctie, en de evaluatiemetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aan de hand van <code>Model.fit</code> kunnen we het model fitten. Achter de schermen minimaliseren we de loss en passen we de parameters aan (= gewichten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: fit het model op de trainingsdata over 5 epochs.\n",
    "Tip: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "'''\n",
    "history = model.fit("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ons model is getraind op de trainingsdata, maar uiteraard zijn we geïnteresseerd in hoe het presteert op examples die het nog niet heeft gezien. Daarom evalueren we het model op de __validatie of test set__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose = 1) #verbose 1 geeft toons ons ook de progressie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen vervolgens eenvoudiger voorspellingen uitlezen door de __softmax in te bouwen.__ Dit is opnieuw een model, dat ons oorspronkelijke model als het ware encapsuleert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Opmerking:* </br>Je zou er natuurlijk ook voor kunnen kiezen om je softmax meteen in je model in te bouwen wanneer je het initialiseert via de <code>Sequential</code> klasse. In dat geval heb je twee opties: \n",
    "- Je definieert de softmax activatiefunctie door dit als parameter aan te geven bij de reeds bestaande laatste Dense laag: <code>tf.keras.layers.Dense(10, activation = 'softmax')</code>\n",
    "- Je wijzigt niets aan je laatste Dense laag, maar voegt de softmax als nieuwe, laatste laag in het model toe: <code>tf.keras.layers.Softmax()</code>. In dit geval heb je dus een Dense laag, gevolgd door een softmax laag.\n",
    "\n",
    "De drie besproken opties zullen hetzelfde resultaat opleveren.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen vervolgens voorspellingen doen (hier voor het eerste voorbeeld in onze testset):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De echte (ground thurth) waarde van dit voorbeeld:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example_y = (np.expand_dims(y_test[1],0))\n",
    "print(\"De echte waarde die hoort bij het eerste trainingsexample:\", test_example_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De voorspelling van ons netwerk. Merk op dat we hier ook de <code>model.predict()</code> zouden kunnen gebruiken. \n",
    "</br>Omdat we werken met een softmax functie, moeten we de waarde uit de rij halen met de hoogste waarde. Dit kan door <code>np.argmax()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example_prediction = (np.expand_dims(x_test[1],0))\n",
    "prediction = probability_model(test_example_prediction)\n",
    "print(\"De voorspelde waarde die hoort bij het eerste testexample:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot maken\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "history_dict = history.history\n",
    "train_acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "# Training en validatie accuracy plotten\n",
    "plt.plot(epochs, train_acc, 'bo-', label='Training accuracy', linewidth=2)\n",
    "plt.plot(epochs, val_acc, 'ro-', label='Validation accuracy', linewidth=2)\n",
    "\n",
    "# Layout verbeteren\n",
    "plt.title('Training en Validation Accuracy', fontsize=14, pad=15)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Y-as aanpassen naar relevant bereik\n",
    "plt.ylim([0.85, 0.95])\n",
    "\n",
    "# X-as ticks voor elke epoch\n",
    "plt.xticks(epochs)\n",
    "\n",
    "# Waardes bij punten\n",
    "for i, (train_value, val_value) in enumerate(zip(train_acc, val_acc)):\n",
    "    plt.text(epochs[i], train_value, f'{train_value:.3f}', \n",
    "             horizontalalignment='right', verticalalignment='bottom')\n",
    "    plt.text(epochs[i], val_value, f'{val_value:.3f}', \n",
    "             horizontalalignment='right', verticalalignment='top')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularisatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularisatie is een manier om overfitting tegen te gaan door bepaalde technieken toe te passen op ons netwerk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__ Hoe kunnen we overfitting tegengaan? Voorzie een van volgende technieken:\n",
    "- L1 of L2 regularisatie (https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1L2)\n",
    "- Early Stopping (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
    "- Dropout (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "- Data augmentatie (https://www.tensorflow.org/tutorials/images/data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TODO: implementeer regularisatietechniek en evalueer het model'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyseren en visualiseren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen gebruik maken van __TensorBoard__ om ons model op een visuele manier te analyseren. Het is een tool die ons toelaat om onder de *loss* en metrics als *accuracy* bij te houden en het model over verschillende trainingsiteraties te visualiseren. Meer info vind je hier: https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om gebruik te kunnen maken van TensorBoard moet de notebook extensie ingeladen worden en dienen we de logs bij te houden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens dient de <code>tf.keras.callbacks.TensorBoard</code> callback toegevoegd worden aan het model, door onderstaande codelijn als argument toe te voegen aan <code>Model.fit()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: voeg de callback toe als argument aan de model.fit() functie.\n",
    "Tip: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback'''\n",
    "model.fit("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen TensorBoard starten via deze notebook via <code>%tensorboard</code>, waarbij we ook de map meegeven waar de logs werden opgeslagen. \n",
    "\n",
    "*Noot: Wanneer je TensorBoard uitvoert, zal je zien dat je links een selectie kan maken van verschillende *runs*. Een run komt overeen met het eenmalig uitvoeren van het <code>model.fit()</code> commando waarbinnen je de callback als parameter hebt meegegeven. Wanneer je dit commando meerder malen uitvoert, beschik je dus ook over meerdere runs die je ook kan visualueren.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volgende dashboards zijn standaard beschikbaar:\n",
    "- __Scalars__: Laat toe om de loss en accuracy te visualiseren, alsook hyperparameters als de learning rate.\n",
    "- __Graphs__: Visualisatie van het model.\n",
    "- __Distribution en histogram__: Distributie van een Tensor gedurende de trainingsperiode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Wat is de accuracy na 3 epochs?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Antwoord__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
